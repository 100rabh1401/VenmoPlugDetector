{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A label of 0 means not illicit content, a label of 1 means illicit content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LetMeScrapeThat(object):\n",
    "    \"\"\"\n",
    "    Using Selenium Webdriver and PhantomJS, we simulate opening the actual website to let\n",
    "    javascript render the target website and update all html codes containing data that we want to extract.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        print(\"Accessing data.\")\n",
    "        self.phantom_webpage = webdriver.PhantomJS()\n",
    "        self.phantom_webpage.set_window_size(1120, 550)\n",
    "\n",
    "    def scrape_vicemo(self, link, howmany = 100):\n",
    "        self.phantom_webpage.get(link)\n",
    "        print('Visiting the data source: {}'.format(link))\n",
    "        print(\"Please, wait.\")\n",
    "        sleep(2)  # We make the scraper wait until the website loads completely\n",
    "        for int in range((howmany // 100)-1):\n",
    "            # each \"scroll\" yields 100 transactions on Venmo; the web driver has to sleep so that all data can load\n",
    "            self.phantom_webpage.execute_script(\"window.scrollTo(0, 10000);\")\n",
    "            sleep(2)\n",
    "\n",
    "        # from the phantom_webpage, find all web elements with the class \"transaction\" and returns the outcome\n",
    "        # as a list variable \"webele\". \"howmany\" controls the number of observed transactions being extracted.\n",
    "        webele = self.phantom_webpage.find_elements_by_class_name(\"transaction\")[:howmany + 1]\n",
    "\n",
    "        # enter list comprehension to extract the HTML codes from each web element\n",
    "        self.transactions = [ele.get_attribute(\"innerHTML\") for ele in webele]\n",
    "        self.datalength = len(self.transactions)\n",
    "        # shuts down the phantom webpage\n",
    "        self.phantom_webpage.quit()\n",
    "\n",
    "class LetMeParseThat(object):\n",
    "    \"\"\"\n",
    "    Using BeautifulSoup, we parse the html extracted from web elements\n",
    "    \"\"\"\n",
    "    def __init__(self,list_of_html):\n",
    "        print(\"Parsing data.\")\n",
    "        self.soup_list = [BeautifulSoup(html, \"html.parser\") for html in list_of_html]\n",
    "        self.desc_tags_compiler =[soup_ele.find_all('div',attrs={'class':'description'}) for soup_ele in self.soup_list]\n",
    "\n",
    "    def extract_string_data(self):\n",
    "        # extracts strings from the <div> tags with class=\"description\"\n",
    "        self.string_compiler = [soup_ele.find('div', attrs={'class':'description'}).string\n",
    "                                for soup_ele in self.soup_list\n",
    "                                if soup_ele.find('div', attrs={'class':'description'}).string]\n",
    "\n",
    "    def extract_emoji_data(self):\n",
    "        # extracts emojis from the <span> tags with class=\"emoji emoji-sizer\"\n",
    "        self.emoji_compiler = []\n",
    "        for soup_ele in self.soup_list:\n",
    "            for span in soup_ele.find_all('span', attrs={'class':['emoji','emoji-sizer']}):\n",
    "                self.emoji_compiler.append(span['title'])\n",
    "\n",
    "class LetMeAnalyzeThat(object):\n",
    "    common_english_words = ['the',\t'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have', 'I', 'it', 'for', 'not', 'on',\n",
    "                         'with', 'he', 'as', 'you',\t'do', 'at', 'this', 'but', 'his', 'by', 'from', 'they', 'we', 'say',\n",
    "                         'her', 'she', 'or', 'an', 'will', 'my', 'one', 'all', 'would', 'there', 'their', 'what', 'so',\n",
    "                         'up', 'out', 'if',\t'about', 'who',\t'get', 'which', 'go', 'me', 'when', 'make', 'can', 'like',\n",
    "                         'time', 'no', 'just', 'him', 'know', 'take', 'people', 'into', 'year', 'your', 'good', 'some',\n",
    "                         'could','them', 'see', 'other', 'than', 'then', 'now', 'look', 'only', 'come', 'its', 'over',\n",
    "                         'think', 'also', 'back', 'after', 'use', 'two', 'how',\t'our', 'work', 'first',\t'well',\t'way',\n",
    "                         'even', 'new',\t'want', 'because', 'any', 'these', 'give', 'day', 'most', 'us', '']\n",
    "    def __init__(self):\n",
    "        print(\"Analyzing data.\")\n",
    "        pass\n",
    "\n",
    "    def analyze_string_data(self, string_data):\n",
    "        \"\"\"\n",
    "        takes a list made up of phrases of strings, cleanses them and adds to vice_compiler\n",
    "        creates a dictionary of unique words and counts their occurances\n",
    "        \"\"\"\n",
    "        vice_compiler = []\n",
    "        for ele in string_data:\n",
    "            for word in ele.split():\n",
    "                # cleanse the word using Regular expression and string methods\n",
    "                regex = re.compile('[^a-zA-Z]')\n",
    "                cleansed_word = regex.sub('',word.lower().rstrip())\n",
    "                vice_compiler.append(cleansed_word)\n",
    "        # creates a dictionary of unique words with zero initial count\n",
    "        # drop the word in the dictionary if it is just a useless common English word\n",
    "        self.vice_str_dict = {key : 0 for key in set(vice_compiler) if key not in self.common_english_words}\n",
    "\n",
    "        for ele in vice_compiler:\n",
    "            if ele in self.vice_str_dict:\n",
    "                self.vice_str_dict[ele] += 1\n",
    "        return self.vice_str_dict\n",
    "\n",
    "    def analyze_emoji_data(self, emoji_data):\n",
    "        \"\"\"\n",
    "        takes a list of strings (names of the emojis), creates a dictionary of unique strings and counts occurences\n",
    "        \"\"\"\n",
    "        # creates a dictionary of unique emojis with zero initial count\n",
    "        self.vice_emoji_dict = {key : 0 for key in set(emoji_data)}\n",
    "        for ele in emoji_data:\n",
    "            if ele in self.vice_emoji_dict:\n",
    "                self.vice_emoji_dict[ele] += 1\n",
    "        return self.vice_emoji_dict\n",
    "\n",
    "class VicemoScraper(object):\n",
    "    def __init__(self, link):\n",
    "        print(\"Starting the Scraper.\")\n",
    "        # commence scraping\n",
    "        # set up a Scraper instance that uses LetMeScrapeThat class\n",
    "        self.scraper = LetMeScrapeThat()\n",
    "        self.scraper.scrape_vicemo(link, howmany=300)\n",
    "\n",
    "    def get_data(self):\n",
    "        # set up a Parser instance that uses LetMeParseThat class\n",
    "        parser = LetMeParseThat(self.scraper.transactions)\n",
    "\n",
    "        # extract string data and emoji data from Venmo transactions\n",
    "        parser.extract_string_data()\n",
    "        parser.extract_emoji_data()\n",
    "\n",
    "        # set up an Analyzer instance that uses LetMeAnalyzeThat class\n",
    "        analyzer = LetMeAnalyzeThat()\n",
    "        self.str_data = analyzer.analyze_string_data(parser.string_compiler)\n",
    "        self.emoji_data = analyzer.analyze_emoji_data(parser.emoji_compiler)\n",
    "        return self.emoji_data, self.str_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/selenium/webdriver/phantomjs/webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'phantomjs' executable needs to be in PATH. \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                             \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                             stdin=PIPE)\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    776\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1521\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1523\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'phantomjs': 'phantomjs'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-29879e5b87cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscraper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLetMeScrapeThat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://www.vicemo.com/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscrape_vicemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLetMeParseThat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1055472739b8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accessing data.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphantom_webpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhantomJS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphantom_webpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_window_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m550\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/selenium/webdriver/phantomjs/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, desired_capabilities, service_args, service_log_path)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mservice_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             log_path=service_log_path)\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 raise WebDriverException(\n\u001b[1;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[0;32m---> 83\u001b[0;31m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[1;32m     84\u001b[0m                 )\n\u001b[1;32m     85\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: 'phantomjs' executable needs to be in PATH. \n"
     ]
    }
   ],
   "source": [
    "scraper = LetMeScrapeThat()\n",
    "link = \"http://www.vicemo.com/\"\n",
    "scraper.scrape_vicemo(link,150)\n",
    "print(scraper.transactions)\n",
    "parser = LetMeParseThat(scraper.transactions)\n",
    "parser.extract_string_data()\n",
    "parser.make_soup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
